# -*- coding: utf-8 -*-
"""s1024044.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/121DglhUFfIAgsbNfjPHXqjQzNKJVPDqx

### Connect colab to googledrive
"""

from google.colab import drive
drive.mount("/content/drive")

""" ### Import MNIST dataset"""

import tensorflow as tf
mnist = tf.keras.datasets.mnist

(x_train, y_train),(x_test, y_test) = mnist.load_data()

"""### Check the shape of training data"""

print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)

"""### Have quick view of the training data"""

y_train[:10]

x_train[0]

"""###Image Enhancement"""

data = x_train[0].copy()
data[data>0]=1

text_image=[]
for i in range(data.shape[0]):
    text_image.append(''.join(str(data[i])))
text_image

"""### Show the first image of the training set"""

import matplotlib.pyplot as plt
X2 =  x_train[0,:]
plt.imshow(X2.reshape(28,28), cmap='gray')
plt.axis('off')
plt.show()

"""### Normalize the pixel"""

x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0

"""### Setup the framework of the training model"""

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import Dropout

#設定架構
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)), ## 1*28*28 ==> 32*26*26
    tf.keras.layers.MaxPool2D(2, 2), ## 32*26*26 ==> 32*13*13
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'), ## 32*13*13 ==> 64*11*11
    tf.keras.layers.MaxPool2D(2, 2), ## 64*11*11 ==> 64*5*5
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Flatten(), ## 64*5*5 ==> 1*(64*5*5) = 1*1600
    tf.keras.layers.Dense(800, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(200, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(50, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax'),
])

"""### Setup the optimizer, loss function and performance metrics"""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""### Perform model training"""

from keras.callbacks import EarlyStopping


early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = model.fit(x_train_norm, y_train, epochs=5, validation_split=0.2, callbacks=[early_stopping])

"""### Plot the performance curve (accuracy)"""

plt.figure(figsize=(8, 6))
plt.plot(history.history['accuracy'], 'r', label='accuracy')
plt.plot(history.history['val_accuracy'], 'g', label='val_accuracy')
plt.legend()

"""### Plot the performance curve (loss)"""

plt.figure(figsize=(8, 6))
plt.plot(history.history['loss'], 'r', label='loss')
plt.plot(history.history['val_loss'], 'g', label='val_loss')
plt.legend()

"""### Scoring the trained model"""

score=model.evaluate(x_test_norm, y_test, verbose=0)

print(score)
for i, x in enumerate(score):
    print(f'{model.metrics_names[i]}: {score[i]:.4f}')

"""### Perform the prediction"""

import numpy as np
predictions = np.argmax(model.predict(x_test_norm),axis=1)
print('actual:   ', y_test[0:20])
print('prediction:', predictions[0:20])

"""### Compute the Prediction Probability of 0 to 9 for the test data"""

predictions = model.predict(x_test_norm[8:9])
print(f'Prediction Probability of 0 to 9: {np.around(predictions[0], 2)}')

"""### Save the trained model"""

model.save('./content/drive/Colab Notebooks/model.h5')

model.save('./drive/MyDrive/20231006/model_test.h5')

"""##Use the trained model"""

from keras.models import load_model

MODEL_PATH = './drive/MyDrive/20231006/model_test.h5'

# Load Model
model = load_model(MODEL_PATH)

df.to_csv()