# -*- coding: utf-8 -*-
"""S102444張鎧馪1027.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wWXso-c2zc3xiiWhb-1smjso04UKIFzH

#Yolov4-tiny (darknet) 自定義資料集訓練範例  
歐尼克斯實境互動工作室 OmniXRI Jack, 2021.5.28  
參考來源：https://github.com/AlexeyAB/darknet

#1. 驗證Nvidia GPU及CUDA版本
確認運行環境（本步驟可略過）  
GPU每次配置可能不同，可能為 K80, T4, P100，記憶體大小可能會影響到後續訓練時Patch Size大小。  
若想要好一點的GPU則重覆斷開連線(Ctrl+M)再重新連線，直到出現期望的GPU出現，再進行下一個步驟。
"""

!nvidia-smi
!/usr/local/cuda/bin/nvcc --version

"""#2. 連接Google Drvie
請先在自己的Google Drive上建立一個yolov4-tiny的空檔案夾，方便後續訓練時可暫存權重檔到此處。
掛載Google Drvie（雲端硬碟），點擊網址(Go to this URL in a browser)，允許連結，再複製授權碼貼到空格（Enter your authorization code）中。  
建立捷徑 /my_drive 指向已掛載之Google Drvie (/content/drive/MyDrive/)
"""

from google.colab import drive

drive.mount('/content/drive')
!ln -s /content/drive/MyDrive/ /my_drive
!ls
!ls /my_drive

"""#3. 下載darknet及Yolov4-tiny預訓練權重檔"""

# 下載darknet
!git clone https://github.com/OmniXRI/Yolov4-tiny_Colab_User_Datasets

!wget -N https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights
!ls

"""#4. 修改Makefile參數
將GPU, CUDNN, CUDNN_HALF, OPENCV設為可用  
GPU=0 --> GPU=1  
CUDNN=0 --> CUDNN=1  
CUDNN_HALF=0 --> CUDNN_HALF=1  
OPENCV=0 --> OPENCV=1
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd darknet
!sed -i 's/GPU=0/GPU=1/' Makefile
!sed -i 's/CUDNN=0/CUDNN=1/' Makefile
!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile
!sed -i 's/OPENCV=0/OPENCV=1/' Makefile

"""#5. 編譯darknet"""

!make

"""#6. 測試darknet編譯結果
1.   檢查目前工作路徑是否在 darknet 路徑
2.   執行darknet物件偵測推論，指定 data, config, weight, image 所在位置(darknet/data/ 路徑下有幾張jpg影像可供測試)。
3.   顯示結果影像predictions.jpg
"""

!ls
!./darknet  detector test cfg/coco.data cfg/yolov4-tiny.cfg ../yolov4-tiny.weights data/dog.jpg

import cv2 # 導入OpenCV函式庫
from google.colab.patches import cv2_imshow # 導入Colab.patches函式庫

imgResult = cv2.imread('predictions.jpg') # 讀入結果影像
cv2_imshow(imgResult) # 顯示結果影像

"""#7. 準備自定義預訓練權重檔、資料集及相關參數檔

從 https://github.com/AlexeyAB/Darknet#how-to-train-tiny-yolo-to-detect-your-custom-objects 下載自定義預訓練權重檔 yolov4.conv.29

從Github中下載自定義資料集和相關參數檔（這個範例已幫大家準備了一份）

資料集(my_dataset.zip)中共有100張影像（＊.jpg，內容為狗臉、貓臉及人臉三種物件）及yolo格式(＊.txt)標註檔。

此資料集僅供學習測試，各影像內容版權屬原作者。建議可自行重新收集、標註，標註工具推薦使用LabelImg https://github.com/tzutalin/labelImg 進行資料標註即可，存檔時記得點選yolo格式。若產生VOC格式則須另外轉換成Yolo格式，這裡不提供轉換程式。

參數檔包含下列內容，可依資料集實際內容進行修改。

*    my_obj.data （物件資料設定，含物件類別、訓練驗證路徑、備份權重路徑）
*    my_obj.names （物件類別名稱，每一列為一個類別名稱）
*    my_yolov4-tiny-custom.cfg （設定模型組態）
*    my_train.txt （訓練內容檔案名稱，取資料集前80組，可自行定義）
*    my_valid.txt （驗證內容檔案名稱，取資料集後20組，可自行定義）

其中第3項my_yolov4-tiny-custom.cfg是從/darknet/cfg/yolov4-tiny-custom.cfg須修改而得，修改內容如下，須依自定義資料集內容而定。
*    line 6 : batch=64 # 可依顯卡記憶體調整
*    line 7 : subdivisions=1 # 可依顯卡記憶體調整
*    line 8 : width=416 # 須為32的倍數
*    line 9 : height=416 # 須為32的倍數
*    line 20 : max_batches=6000 # 類別數量(classes)x2000，目前類別數量為3
*    line 22 : steps=4800,5400 # 為max_batch值的 80%, 90%
*    line 212, 263 : filter=255 # 為(classes+5)x3
*    line 220, 269 : classes=3 # 物件類別數量

最後將相關參數檔複製到/darknet對應路徑下。  
"""

# Commented out IPython magic to ensure Python compatibility.
#回到使用者根目錄
# %cd /content
# 下載yolov4-tiny自定義權重檔yolov4-tiny.conv.29(18.8MB)
!wget -N https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29
# 下載資料集和相關參數檔
!git clone https://github.com/OmniXRI/Yolov4-tiny_Colab_User_Datasets
!ls
# 相關參數到對應路徑下
!cp Yolov4-tiny_Colab_User_Datasets/my_yolov4-tiny-custom.cfg darknet/cfg/
!cp Yolov4-tiny_Colab_User_Datasets/my_obj.data darknet/data/
!cp Yolov4-tiny_Colab_User_Datasets/my_obj.names darknet/data/
!cp Yolov4-tiny_Colab_User_Datasets/my_train.txt darknet/data/
!cp Yolov4-tiny_Colab_User_Datasets/my_val.txt darknet/data/
# 將資料集解壓縮到指定路徑
!unzip Yolov4-tiny_Colab_User_Datasets/my_dataset.zip -d darknet/data
!ls darknet/data/my_dataset/

!pwd

!unzip data.zip -d darknet/data
!ls darknet/data/data/

!sed -i 's/my_dataset/data/' data/my_train.txt
!sed -i 's/my_data/data/' data/my_val.txt

"""#8. 開始訓練  
##8.1 正常重新訓練  
指定.data, .cfg, 預訓練參數檔並開始訓練，如需記錄平均精確度mAP(mean average precisions)可加上參數 -map。如果訓練過程很容易無故中止則建議移除參數 -map。  

訓練期間會記錄Loss並繪成圖表(darknet/chart_my_yolov4-tiny-custom.png)，可隨時重新開啟觀察訓練成果。  

每隔1000次會自動備份一次權重檔到雲端硬碟/my_drive/yolov4-tiny下(根據my_obj.data中backup設定值)，檔名為my_yolov4-tiny_x000.weights (x為1~n)。  

訓練期間會自動產生my_yolov4-tiny_best.weights和my_yolov4-tiny_last.weights，完成訓練會產生my_yolov4-tiny_final.weights。  

這裡要注意雲端硬體要有足夠空間存放，否則空間不足時就無法備份權重值。
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/darknet
!./darknet detector train data/my_obj.data cfg/my_yolov4-tiny-custom.cfg ../yolov4-tiny.conv.29 -map

"""##8.2 重新接續執行訓練  
前一步驟有設定備份訓練過程的權重檔，若遇到執行到一半就斷線，此時可以從Google Drive中把最後一次權重檔 my_yolov4-tiny-custom_last.weights 複製到Colab darknet/backup下，再重新啟動訓練。
"""

!cp /my_drive/yolov4-tiny_1027/my_yolov4-tiny-custom_last.weights backup/
!ls backup/

!./darknet detector train data/my_obj.data cfg/my_yolov4-tiny-custom.cfg backup/my_yolov4-tiny-custom_last.weights -map -dont_show

"""#9. 測試訓練結果  
1.   完成訓練後，可將結果權重檔my_yolov4-tiny-custom_final.weights複製到Colab虛擬機中。
2.   執行darknet物件偵測推論，指定 data, config, weight, image 所在位置，/Yolov4-tiny_Colab_User_Datasets下有test01.jpg和test02.jpg可供測試。
3.   顯示結果影像predictions.jpg
"""

!pwd

!cp /my_drive/yolov4-tiny_1027/my_yolov4-tiny-custom_last.weights ../

!./darknet detector test data/my_obj.data cfg/my_yolov4-tiny-custom.cfg ../my_yolov4-tiny-custom_last.weights ../Yolov4-tiny_Colab_User_Datasets/test01.jpg
import cv2 # 導入OpenCV函式庫
from google.colab.patches import cv2_imshow # 導入Colab.patches函式庫

imgResult = cv2.imread('predictions.jpg') # 讀入結果影像
cv2_imshow(imgResult) # 顯示結果影像

import matplotlib.pyplot as plt
import cv2

image = cv2.imread('predictions.jpg')
plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))

plt.show()

!cp /my_drive/yolov4-tiny_1027/my_yolov4-tiny-custom_last.weights ../

!./darknet detector train data/my_obj.data cfg/my_yolov4-tiny-custom.cfg ../my_yolov4-tiny-custom_last.weights ../img_940.jpg
import cv2 as cv
#from google.colab.patches import cv2_imshow

imgResult = cv.imread('predictions.jpg')
cv2.imshow(imgResult)